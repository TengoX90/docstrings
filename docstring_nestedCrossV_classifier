 """
    Class function that performs nested cross validation with KNN classification. It uses the KNN_Classifer as 
    inherited class function to compute best grid and train models.
    It takes five initiation arguments, number of nearest neighbors, distance metric type, index fold splitting, 
    size of the splitting data and random seed for data permutation. It also takes the data set and the class label 
    provided in the fit method as input data to run the class. For
    instance, the standard way of implementing the class function should include the class followed by fit method and 
    displaying results method. See example below:
    
    Example:
    --------
    >>> model = KNN_NestedCrossV(k, metric_type, nfolds, split_size, seed)
    >>> model.fit(data_set, labels)
    >>> model.disply_results()

    
    Parameters:
    -----------
    k : number of nearest neighbors to use for classification. This argument can have a range of any 
    integer number not greater than the data size.
    
    metric_type : Is the way of how the distance between data points are measured. 
    The metric type could be either 'euclidean' or 'manhattan'.
    
    nfolds : Defines the value for the split of the data indices. It could be only an integer otherwise it will raise an error.
    See Error raised section below.
    
    split_size : Integer that bounds the size of the data for cross validation so the data could be split in equal parts.
    
    seed : seed could be any integer number that will represent the combination of random permutation. For more 
    details see numpy.random.seed on: <https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.seed.html>_ 
    
    Methods:
    --------
    ___init__(k, metric_type, nfolds, split_size, seed)
            Create class initiation with all the parameters described above.
    fit(X, y)
            The method fits the data to run the KNN nested cross validation class. It takes two arguments, 
            data and labels.See example above.
    nested_crossV()
            It loops indices through all the permutations necessary to cross validate the datasets.
    inner_loop1(self, X_train, y_train, X_valid, y_valid, X_test, y_test)
            The method takes all the dataset from the nested cross validation and loops through to defines best 
            knn grid parameters.
    inner_loop2(self, X_valid, y_valid, X_test, y_test)
            It loops all the validation datasets to test them and determine the best validation set per round.
    disply_results()
            It is the outer loop that cycles through all sequences to display results necessary.
            
    Error raised:
    -------------
    If k is not an integer it will raise a TypeError:
    If metric type is neither 'euclidean' nor 'manhattan' it will raise a UnboundLocalError:
    If nfolds is not an integer it will raise a TypeError:
    If split size is not an integer it will raise a TypeError:
    If data and class labels are not the same size it will raise a AssertionError:
    If one of the arguments are not provide it raises a TypeError:
    
    """
